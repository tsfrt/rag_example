{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1817a234-e88e-4945-92c6-a74d2386ec08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -qqqq mlflow-skinny[databricks] langgraph==0.3.4 databricks-langchain databricks-agents psycopg2-binary uv\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4413a0b3-0e29-4719-9ff2-653f105e4370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\n",
    "    \"vector_index\",\n",
    "    \"pgvector_index4\",\n",
    "    label=\"vector index name used for naming model endpoint, function, etc\",\n",
    ")\n",
    "\n",
    "dbutils.widgets.text(\n",
    "    \"embedding_model\",\n",
    "    \"databricks-gte-large-en\",\n",
    "    label=\"embedding model to use\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f493499f-fd9e-41ee-8fc2-c0c12b2e8c0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "{'host': 'instance-d25b042e-1736-4852-8dbe-1f1e4fe0efe2.database.cloud.databricks.com',\n",
       " 'database': 'databricks_postgres',\n",
       " 'user': 'vector_db',\n",
       " 'password': 'abc123456789'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the Databricks host and token\n",
    "import os, json\n",
    "\n",
    "os.environ['DATABRICKS_TOKEN'] = dbutils.secrets.get(scope=\"gsa-rag\", key=\"endpoint-token\")\n",
    "conn_params = json.loads(dbutils.secrets.get(scope=\"gsa-rag\", key=\"vector-conn-params\"))\n",
    "os.environ['INDEX_PARAMS'] = json.dumps(conn_params)\n",
    "display(conn_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39428e90-d9c3-4696-823b-390033196010",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-2d9b823d-3781-488b-bd19-5dff074c5b50/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001B[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001B[0m\n  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "import psycopg2\n",
    "import json\n",
    "import os, sys\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "\n",
    "class VectorIndexModel(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        None\n",
    "\n",
    "    def get_embedding(self, input_text):\n",
    "        client = WorkspaceClient()\n",
    "        response = client.serving_endpoints.query(\n",
    "            name=\"databricks-gte-large-en\", input=input_text\n",
    "        )\n",
    "\n",
    "        return response.data[0].embedding\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        query = model_input[\"input\"][0]\n",
    "        num_docs = model_input[\"num_docs\"][0]\n",
    "        sensitivities = model_input[\"sensitivity\"][0]\n",
    "\n",
    "        conn_params=os.getenv(\"INDEX_PARAMS\")\n",
    "        conn_params = json.loads(conn_params)\n",
    "\n",
    "        pre_computed_embedding = self.get_embedding(query)\n",
    "        embedding_str = \",\".join(map(str, pre_computed_embedding))\n",
    "        sensitivitites_pred = \",\".join([f\"'{element}'\" for element in sensitivities])\n",
    "        \n",
    "        conn = psycopg2.connect(**conn_params)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        sql_query = f\"\"\"\n",
    "        SELECT id, doc_url, content, sensitivity\n",
    "        FROM document_base\n",
    "        WHERE sensitivity = ANY(ARRAY[{sensitivitites_pred}])\n",
    "        ORDER BY embedding <-> '[{embedding_str}]'::vector\n",
    "        LIMIT {num_docs};\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_query)\n",
    "        results = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "        column_names = [desc[0] for desc in cursor.description]\n",
    "        json_results = [dict(zip(column_names, row)) for row in results]\n",
    "\n",
    "        return {\"outputs\": json_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da960c19-caa5-4632-be04-3b3d7f0cac0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'outputs': [{'id': 253,\n",
       "   'doc_url': '/Volumes/tsfrt/gsa/performance/FY-2026-GSA-Annual-Performance-Plan_5-28-25.pdf',\n",
       "   'content': \"ERROR: Error code: 400 - {'error_code': 'BAD_REQUEST', 'message': 'Request size cannot exceed 4194304 bytes. Please shorten the request.'}\",\n",
       "   'sensitivity': 'public'},\n",
       "  {'id': 150,\n",
       "   'doc_url': '/Volumes/tsfrt/gsa/performance/GSA_Annual_Performance_Plan_FY_2023_FINAL_508.pdf',\n",
       "   'content': \"ERROR: Error code: 400 - {'error_code': 'BAD_REQUEST', 'message': 'Invalid base64 string for image\\\\n'}\",\n",
       "   'sensitivity': 'public'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorIndexModel = VectorIndexModel()\n",
    "\n",
    "vectorIndexModel.predict(\n",
    "    context={},\n",
    "    model_input={\n",
    "        \"input\": \"what is gsa?\", \n",
    "        \"num_docs\": \"2\", \n",
    "        \"sensitivity\": [[\"public\"]]\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71192ce1-8705-40f1-98a1-b09c45fa4a9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/05 02:03:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n\uD83D\uDD17 View Logged Model at: https://e2-demo-field-eng.cloud.databricks.com/ml/experiments/1945536872982684/models/m-aea9bd037e36421f8a2a08fa2cc1febb?o=1444828305810485\n2025/08/05 02:03:41 INFO mlflow.pyfunc: Validating input example against model signature\n2025/08/05 02:03:41 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlflow.models.model.ModelInfo object at 0x7f830ba667d0>\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types import Schema, ColSpec\n",
    "from mlflow.models.resources import DatabricksServingEndpoint\n",
    "from mlflow.types.schema import Schema, ColSpec, Array\n",
    "from mlflow.types import DataType\n",
    "\n",
    "resources = [DatabricksServingEndpoint(endpoint_name=\"databricks-gte-large-en\")]\n",
    "\n",
    "input_example = {\"input\": \"text chunk\", \"num_docs\": \"2\", \"sensitivity\": [\"public\"]}\n",
    "conn_params_path = \"conn_params.json\"\n",
    "\n",
    "# Start an MLflow run and log the model\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"pgvector-query\",\n",
    "        signature=ModelSignature(\n",
    "            inputs=Schema(\n",
    "                [\n",
    "                    ColSpec(\"string\", \"input\"),\n",
    "                    ColSpec(\"string\", \"num_docs\"),\n",
    "                    ColSpec(Array(DataType.string), \"sensitivity\"),\n",
    "                ]\n",
    "            ),\n",
    "            outputs=Schema(\n",
    "                [\n",
    "                    ColSpec(\"long\", \"id\"),\n",
    "                    ColSpec(\"string\", \"content\"),\n",
    "                    ColSpec(\"string\", \"sensitivity\"),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        python_model=VectorIndexModel(),\n",
    "        input_example=input_example,\n",
    "        resources=resources,\n",
    "        pip_requirements=[\n",
    "            \"mlflow==3.1.4\",\n",
    "            \"cloudpickle==3.0.0\",\n",
    "            \"httplib2==0.20.2\",\n",
    "            \"psycopg2-binary==2.9.10\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "print(logged_agent_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c03d1cb-4f5d-46b8-ac8b-7b1360273bcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'tsfrt.gsa.pgvector_index4' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e503012a2a34fb78b9eed61caa133c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5ae2523296417ba876c91b9162f420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 Created version '6' of model 'tsfrt.gsa.pgvector_index4': https://e2-demo-field-eng.cloud.databricks.com/explore/data/models/tsfrt/gsa/pgvector_index4/version/6?o=1444828305810485\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "vector_index = dbutils.widgets.get(\"vector_index\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"tsfrt\"\n",
    "schema = \"gsa\"\n",
    "model_name = vector_index\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0d9a1ad-3dc9-47e6-a0be-90a3f4e2fc41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint pgvector_index4-endpoint already exists.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark-2d9b823d-3781-488b-bd19-5d/.ipykernel/54043/command-7424973428831990-2375028618:24: FutureWarning: ``mlflow.deployments.databricks.DatabricksDeploymentClient.update_endpoint`` is deprecated. This method will be removed in a future release. Use ``update_endpoint_config, update_endpoint_tags, update_endpoint_rate_limits, or update_endpoint_ai_gateway`` instead.\n  endpoint = client.update_endpoint(endpointname, config=endpoint_config)\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-2d9b823d-3781-488b-bd19-5dff074c5b50/lib/python3.11/site-packages/mlflow/deployments/databricks/__init__.py:543: UserWarning: The `update_endpoint` method is deprecated. Use the specific update methods—`update_endpoint_config`, `update_endpoint_tags`, `update_endpoint_rate_limits`, `update_endpoint_ai_gateway`—instead.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.deployments import get_deploy_client\n",
    "from mlflow.exceptions import MlflowException\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "client = get_deploy_client(\"databricks\")\n",
    "\n",
    "endpointname = f\"{vector_index}-endpoint\"\n",
    "endpoint_config = {\n",
    "    \"served_entities\": [\n",
    "        {\n",
    "            \"entity_name\": UC_MODEL_NAME,\n",
    "            \"entity_version\": uc_registered_model_info.version,\n",
    "            \"workload_size\": \"Small\",\n",
    "            \"scale_to_zero_enabled\": True,\n",
    "            \"environment_vars\": {\"INDEX_PARAMS\": json.dumps(conn_params)},\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    endpoint = client.get_endpoint(endpointname)\n",
    "    print(f\"Endpoint {endpointname} already exists.\")\n",
    "    endpoint = client.update_endpoint(endpointname, config=endpoint_config)\n",
    "except MlflowException as e:\n",
    "    if \"RESOURCE_ALREADY_EXISTS\" in str(e):\n",
    "        print(f\"Endpoint {endpointname} does not exist\")\n",
    "        endpoint = client.create_endpoint(endpointname, config=endpoint_config)\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "context = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\n",
    "workspace_url = context.apiUrl().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42b56e12-a069-4d76-90b2-c28eb97154bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = os.getenv(\"DATABRICKS_TOKEN\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION tsfrt.gsa.vector_query_{vector_index}(input_text STRING, num_docs STRING, sensitivity ARRAY<STRING>)\n",
    "RETURNS STRING\n",
    "LANGUAGE PYTHON\n",
    "AS $$\n",
    "import requests\n",
    "import json\n",
    "\n",
    "token = f'Bearer {token}'\n",
    "\n",
    "url = '{workspace_url}/serving-endpoints/{endpointname}/invocations'\n",
    "\n",
    "headers = {{\n",
    "      'Authorization': token,\n",
    "      'Content-Type': 'application/json'\n",
    "}}\n",
    "data = {{\"input\": input_text, \"num_docs\": num_docs, \"sensitivity\": sensitivity}}\n",
    "try:\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response.raise_for_status()\n",
    "except requests.exceptions.RequestException as e:\n",
    "    raise Exception(f'Request failed: {{e}}')\n",
    "  \n",
    "return response.json()['outputs']\n",
    "$$;\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_41a50460-c90b-4840-9288-afcb847395d5",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7424973428846690,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "03_pgvector_model_notebook",
   "widgets": {
    "embedding_model": {
     "currentValue": "databricks-gte-large-en",
     "nuid": "3ccf0cbf-f3ac-4968-981e-5d2496628238",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "databricks-gte-large-en",
      "label": "embedding model to use",
      "name": "embedding_model",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "databricks-gte-large-en",
      "label": "embedding model to use",
      "name": "embedding_model",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "vector_index": {
     "currentValue": "pgvector_index4",
     "nuid": "6c01a465-73a0-4336-8d7c-d4a2df3527d4",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "pgvector_index4",
      "label": "vector index name used for naming model endpoint, function, etc",
      "name": "vector_index",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "pgvector_index4",
      "label": "vector index name used for naming model endpoint, function, etc",
      "name": "vector_index",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}